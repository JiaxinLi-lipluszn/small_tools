{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process_barcode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7522/4080736814.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_barcode(barcode, **kwargs):\n",
    "    \"\"\"\n",
    "    Process a cell barcode and extract its main body, lane number, and suffix.\n",
    "    You can define the separators by input them into **kwargs\n",
    "\n",
    "    Parameters:\n",
    "    barcode (str): The cell barcode\n",
    "    seps (list): a list of separators in order\n",
    "    parts (list): a list of names of parts in order\n",
    "\n",
    "    Returns:\n",
    "    tuple: a dictionary of all parts in the barcode.\n",
    "\n",
    "    Example Usage:\n",
    "    params = {\n",
    "    \"seps\" : ['#', '-'],\n",
    "    \"parts\" :['lane', 'barcode', 'suffix']\n",
    "    }\n",
    "\n",
    "    archR_barcodes_sep = df['x'].apply(lambda x: pd.Series(process_barcode(barcode=x, **params)))\n",
    "\n",
    "    \"\"\"\n",
    "    assert(\"seps\" in kwargs.keys() and \"parts\" in kwargs.keys())\n",
    "    assert(len(kwargs['seps']) == len(kwargs['parts']) - 1)\n",
    "\n",
    "    ret_dic = {}\n",
    "\n",
    "    for i, sep in enumerate(kwargs['seps']):\n",
    "        parts = barcode.split(sep, 1)\n",
    "        ret_dic[kwargs['parts'][i]] = parts[0]\n",
    "        barcode = parts[1]\n",
    "    \n",
    "    ret_dic[kwargs['parts'][-1]] = barcode\n",
    "\n",
    "    return ret_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/jiaxinli/Downloads/archR_barcodes.csv\", index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lane3#AAACAGCCAACCTAAT-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lane2#AAACAGCCAACTGGCT-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lane4#AAACAGCCAAGCCAGA-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lane2#AAACAGCCAAGCTAAA-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lane1#AAACAGCCAAGGTAAC-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48238</th>\n",
       "      <td>lane2#TTTGTTGGTTCAAGCA-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48239</th>\n",
       "      <td>lane3#TTTGTTGGTTCCTCCT-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48240</th>\n",
       "      <td>lane4#TTTGTTGGTTGGCCGA-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48241</th>\n",
       "      <td>lane1#TTTGTTGGTTTAACGG-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48242</th>\n",
       "      <td>lane3#TTTGTTGGTTTATTCG-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48242 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              x\n",
       "1      lane3#AAACAGCCAACCTAAT-1\n",
       "2      lane2#AAACAGCCAACTGGCT-1\n",
       "3      lane4#AAACAGCCAAGCCAGA-1\n",
       "4      lane2#AAACAGCCAAGCTAAA-1\n",
       "5      lane1#AAACAGCCAAGGTAAC-1\n",
       "...                         ...\n",
       "48238  lane2#TTTGTTGGTTCAAGCA-1\n",
       "48239  lane3#TTTGTTGGTTCCTCCT-1\n",
       "48240  lane4#TTTGTTGGTTGGCCGA-1\n",
       "48241  lane1#TTTGTTGGTTTAACGG-1\n",
       "48242  lane3#TTTGTTGGTTTATTCG-1\n",
       "\n",
       "[48242 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lane3#AAACAGCCAACCTAAT-1'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lane': 'lane3', 'barcode': 'AAACAGCCAACCTAAT', 'suffix': '1'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_barcode(df['x'][1], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"seps\" : ['#', '-'],\n",
    "    \"parts\" :['lane', 'barcode', 'suffix']\n",
    "}\n",
    "\n",
    "archR_barcodes_sep = df['x'].apply(lambda x: pd.Series(process_barcode(barcode=x, **params)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATAC_barcodes = pd.read_csv(\"/Users/jiaxinli/Downloads/Dataset6_sample_1.atac.qc.hg38.metadata.tsv\", sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"seps\" : ['_', '_', '_'],\n",
    "    \"parts\" :['barcode', 'dataset', 'sample', 'suffix']\n",
    "}\n",
    "\n",
    "ATAC_barcodes_sep = ATAC_barcodes['barcode'].apply(lambda x: pd.Series(process_barcode(x, **params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46056"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ATAC_barcodes_sep['barcode'].isin(archR_barcodes_sep['barcode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12306"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(archR_barcodes_sep.loc[archR_barcodes_sep['lane'] == 'lane1', 'barcode'].isin(ATAC_barcodes_sep['barcode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12306"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(archR_barcodes_sep.loc[archR_barcodes_sep['lane'] == 'lane1', 'barcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48242"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(archR_barcodes_sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46905"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(archR_barcodes_sep['barcode']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>barcode</th>\n",
       "      <th>dataset</th>\n",
       "      <th>sample</th>\n",
       "      <th>suffix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAACAGCCAAACCTTG</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAACAGCCAAACGCGA</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAACAGCCAAACGGGC</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAACAGCCAAAGCGCA</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAACAGCCAAAGCTAA</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352182</th>\n",
       "      <td>TTTGTTGGTTTGAGGC</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352183</th>\n",
       "      <td>TTTGTTGGTTTGCAGA</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352184</th>\n",
       "      <td>TTTGTTGGTTTGGCTT</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352185</th>\n",
       "      <td>TTTGTTGGTTTGGGCG</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352186</th>\n",
       "      <td>TTTGTTGGTTTGGGTA</td>\n",
       "      <td>Dataset6</td>\n",
       "      <td>sample</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352187 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 barcode   dataset  sample suffix\n",
       "0       AAACAGCCAAACCTTG  Dataset6  sample      1\n",
       "1       AAACAGCCAAACGCGA  Dataset6  sample      1\n",
       "2       AAACAGCCAAACGGGC  Dataset6  sample      1\n",
       "3       AAACAGCCAAAGCGCA  Dataset6  sample      1\n",
       "4       AAACAGCCAAAGCTAA  Dataset6  sample      1\n",
       "...                  ...       ...     ...    ...\n",
       "352182  TTTGTTGGTTTGAGGC  Dataset6  sample      1\n",
       "352183  TTTGTTGGTTTGCAGA  Dataset6  sample      1\n",
       "352184  TTTGTTGGTTTGGCTT  Dataset6  sample      1\n",
       "352185  TTTGTTGGTTTGGGCG  Dataset6  sample      1\n",
       "352186  TTTGTTGGTTTGGGTA  Dataset6  sample      1\n",
       "\n",
       "[352187 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ATAC_barcodes_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abc', 'abc']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"abc\\tabc\"\n",
    "a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomewideGenerator(torch.utils.data.Dataset):\n",
    "    \"\"\"A data generator for dragonnfruit inputs. Adapted from bpnet-lite.\n",
    "\n",
    "    This generator takes in a set of sequences and output signals \n",
    "    and will return a single element with random jitter and reverse-complement \n",
    "    augmentation applied. Because the data is single-cell where the output\n",
    "    signals differ across cells, each returned element is a random locus\n",
    "    in a random cell. \n",
    "\n",
    "    A conceptual difference between this DataGenerator and the one implemented\n",
    "    in bpnet-lite is that the bpnet-lite one assumes that you can extract all\n",
    "    loci into an array. Here, because there are hundreds of thousands of peaks\n",
    "    and potentially thousands of cells, it is actually more efficient to \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sequences: dict of torch.tensors, shape=(n, 4), dtype=torch.float32\n",
    "        A dictionary of the nucleotide sequences to use.\n",
    "\n",
    "    signals: dict of torch.tensors, shape=(n, n_cells), dtype=torch.float32\n",
    "        A dictionary of the cell signals\n",
    "\n",
    "    loci: str or pandas.DataFrame\n",
    "        A set of loci to use.\n",
    "    \n",
    "    cell_states: \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sequence, signal, neighbors, cell_states, \n",
    "        read_depths, trimming, window, chroms, cells_per_loci=1, \n",
    "        reverse_complement=True, random_state=None):\n",
    "        self.trimming = trimming\n",
    "        self.window = window\n",
    "        self.chroms = chroms\n",
    "        self.cells_per_loci = cells_per_loci\n",
    "        self.reverse_complement = reverse_complement\n",
    "        self.random_state = numpy.random.RandomState(random_state)\n",
    "\n",
    "        self.signal = {chrom: signal[chrom] for chrom in chroms}\n",
    "        self.sequence = {chrom: sequence[chrom] for chrom in chroms}\n",
    "        self.neighbors = neighbors\n",
    "        self.cell_states = cell_states\n",
    "        self.read_depths = read_depths\n",
    "        self._lengths = numpy.array([seq.shape[0] for seq in self.sequence.values()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self._lengths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        c_idx = numpy.random.choice(len(self._lengths), \n",
    "            p=self._lengths / self._lengths.sum())\n",
    "        chrom = self.chroms[c_idx]\n",
    "\n",
    "        mid = numpy.random.randint(10000, self._lengths[c_idx]-10000)\n",
    "        cell_idx = numpy.random.randint(self.cell_states.shape[0])\n",
    "        return _extract_example(self, chrom, mid, cell_idx, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_example(self, chrom, mid, cell_idx, idx):\n",
    "    \"\"\"An internal function for extracting a single example.\n",
    "\n",
    "    This function will extract an example from a given position in a given\n",
    "    cell and handle adding jitter, creating the dynamic pseudobulk, and\n",
    "    potentially reverse complementing the sequence. It will return the\n",
    "    one-hot encoded sequence, signal, cell representation, and read depth\n",
    "    of that cell.\n",
    "\n",
    "    Note that this function returns a *single* example and that the data\n",
    "    generators below handle the creation of batches by repeatedly calling this\n",
    "    function and concatenating the examples.\n",
    "\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    self: torch.utils.data.Dataset\n",
    "        This is one of the data generators defined below. Although they may\n",
    "        differ in how loci and cells are selected, they share the same logic\n",
    "        for how to extract the inputs given a cell and location.\n",
    "\n",
    "    chrom: str\n",
    "        The chromosome name to extract from.\n",
    "\n",
    "    mid: int\n",
    "        The middle position to extract a window around.\n",
    "\n",
    "    cell_idx: int\n",
    "        The integer index of the cell to operate on.\n",
    "\n",
    "    idx: int\n",
    "        The index being generated. Necessary when reverse complementing every\n",
    "        even sequence.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X: torch.Tensor, shape=(4, 2114)\n",
    "        The one-hot encoded sequence\n",
    "\n",
    "    y: torch.Tensor, shape=(1000,)\n",
    "        The signal to be predicted\n",
    "\n",
    "    c: torch.Tensor, shape=(50,)\n",
    "        The cell representation to be extracted.\n",
    "\n",
    "    r: torch.Tensor, shape=(1,)\n",
    "        The read depth of that particular cell.\n",
    "    \"\"\"\n",
    "\n",
    "    start, end = mid - self.window // 2, mid + self.window // 2\n",
    "    neighbs = self.neighbors[cell_idx]\n",
    "\n",
    "    X = self.sequence[chrom][start:end].T.astype('float32')\n",
    "    y = self.signal[chrom][:, start+self.trimming:end-self.trimming]\n",
    "    y = numpy.array(y[neighbs].sum(axis=0))[0]\n",
    "\n",
    "    c = self.cell_states[cell_idx]\n",
    "    r = self.read_depths[cell_idx]\n",
    "\n",
    "    if self.reverse_complement and idx % 2 == 0:\n",
    "        X = X[::-1][:, ::-1].copy()\n",
    "        y = y[::-1].copy()\n",
    "\n",
    "    X = torch.from_numpy(X)\n",
    "    y = torch.from_numpy(y)\n",
    "    c = torch.from_numpy(c)\n",
    "    r = torch.from_numpy(r)\n",
    "    return X, y, c, r\n",
    "∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiC visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from . GenomeTrack import GenomeTrack\n",
    "from pygenometracks.utilities import InputError\n",
    "from intervaltree import IntervalTree, Interval\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib.patches import Arc, Polygon\n",
    "from .. utilities import opener, to_string, change_chrom_names, temp_file_from_intersect, get_region\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from . GenomeTrack import GenomeTrack\n",
    "from pygenometracks.utilities import InputError\n",
    "from intervaltree import IntervalTree, Interval\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "from matplotlib.patches import Arc, Polygon\n",
    "from .. utilities import opener, to_string, change_chrom_names, temp_file_from_intersect, get_region\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEFAULT_LINKS_COLOR = 'blue'\n",
    "HUGE_NUMBER = int(1e9)  # Which should be above any chromosome size\n",
    "\n",
    "\n",
    "class LinksTrack(GenomeTrack):\n",
    "    SUPPORTED_ENDINGS = ['.arcs', '.arc', '.link', '.links', '.bedpe']\n",
    "    TRACK_TYPE = 'links'\n",
    "    OPTIONS_TXT = GenomeTrack.OPTIONS_TXT + f\"\"\"\n",
    "# the file format for links is (tab separated)\n",
    "#   chr1 start1 end1 chr2 start2 end2 (score ...)\n",
    "# The score field is optional\n",
    "# The fields after the score field will be ignored\n",
    "# for example:\n",
    "#   chr1 100 200 chr1 250 300 0.5\n",
    "# depending on the value of links_type either 'arcs' or 'triangles' or 'loops'\n",
    "# or 'squares' can be plotted.\n",
    "# If arcs, an arc will be drawn linking the beginning of the first region (chr1: 100),\n",
    "# to the end of the other region (chr1: 300) except if use_middle is set to true.\n",
    "# If triangles, the vertix of the triangle will be drawn at the center between the two points\n",
    "# (also the extremity of each position is used)\n",
    "# If loops, a diamond highlighting the intersection between the 2 regions will be shown\n",
    "# the triangles, and loops options are convenient to overlay over a\n",
    "# Hi-C matrix to highlight the matrix pixel of the highlighted link.\n",
    "# If squares, a rectangle highlighting the intersection between the 2 regions will be shown\n",
    "# In this case the y axis represent region2 which can be specified\n",
    "# By default it is the same as the region of the x-axis\n",
    "#region2 = X:3000000-3500000\n",
    "# For these tracks do not hesitate to put large line_width like 5 or 10.\n",
    "links_type = arcs\n",
    "# For triangles and arcs, by default the extremities coordinates are used\n",
    "# To use the middle of start1 and end1 and the middle of start2 and end2\n",
    "#use_middle = true\n",
    "# color of the lines\n",
    "color = red\n",
    "# if color is a valid colormap name (like RdYlGn),\n",
    "# then the score is mapped to the colormap.\n",
    "#color = RdYlGn\n",
    "# To set the minimum and maximum value of the colormap:\n",
    "#min_value = 0\n",
    "#max_value = 1.2\n",
    "# To use transparency, you can use alpha\n",
    "# default is 0.8\n",
    "# alpha = 0.5\n",
    "# if line_width is not given, the score is used to set the line width\n",
    "# using the following formula (0.5 * square root(score)\n",
    "#line_width = 0.5\n",
    "# options for line_style are 'solid', 'dashed', 'dotted', and 'dashdot'\n",
    "line_style = solid\n",
    "# If you want to compact the arcs (when you have both long and short arcs)\n",
    "# You can choose a compact level of\n",
    "# 1 (the height is proportional to the square root of the distance)\n",
    "# 2 (the height is the same for all distances)\n",
    "# (default is 0 proportional to distance)\n",
    "#compact_arcs_level = 2\n",
    "# To be able to see small arcs when big arcs exists, you can set\n",
    "# the upper y limit.\n",
    "# The unit is bp. This corresponds to the longest arc you will see.\n",
    "# This option is incompatible with compact_arcs_level = 2\n",
    "#ylim = 100000\n",
    "file_type = {TRACK_TYPE}\n",
    "    \"\"\"\n",
    "    DEFAULTS_PROPERTIES = {'links_type': 'arcs',\n",
    "                           'line_width': None,\n",
    "                           'line_style': 'solid',\n",
    "                           'orientation': None,\n",
    "                           'color': DEFAULT_LINKS_COLOR,\n",
    "                           'alpha': 0.8,\n",
    "                           'max_value': None,\n",
    "                           'min_value': None,\n",
    "                           'region': None,  # Cannot be set manually but is set by tracksClass\n",
    "                           'ylim': None,\n",
    "                           'compact_arcs_level': '0',\n",
    "                           'use_middle': False,\n",
    "                           'region2': None}\n",
    "    NECESSARY_PROPERTIES = ['file']\n",
    "    SYNONYMOUS_PROPERTIES = {'max_value': {'auto': None},\n",
    "                             'min_value': {'auto': None},\n",
    "                             'ylim': {'auto': None}}\n",
    "    POSSIBLE_PROPERTIES = {'orientation': [None, 'inverted'],\n",
    "                           'links_type': ['arcs', 'triangles', 'loops', 'squares'],\n",
    "                           'line_style': ['solid', 'dashed',\n",
    "                                          'dotted', 'dashdot'],\n",
    "                           'compact_arcs_level': ['0', '1', '2']}\n",
    "    BOOLEAN_PROPERTIES = ['use_middle']\n",
    "    STRING_PROPERTIES = ['file', 'file_type', 'overlay_previous',\n",
    "                         'orientation', 'links_type', 'line_style',\n",
    "                         'title', 'color', 'compact_arcs_level',\n",
    "                         'region2']\n",
    "    FLOAT_PROPERTIES = {'max_value': [- np.inf, np.inf],\n",
    "                        'min_value': [- np.inf, np.inf],\n",
    "                        'ylim': [0, np.inf],\n",
    "                        'alpha': [0, 1],\n",
    "                        'line_width': [0, np.inf],\n",
    "                        'height': [0, np.inf]}\n",
    "    INTEGER_PROPERTIES = {}\n",
    "    # The color can be a color or a colormap (if there is a score)\n",
    "\n",
    "    def set_properties_defaults(self):\n",
    "        super(LinksTrack, self).set_properties_defaults()\n",
    "        self.max_height = None\n",
    "\n",
    "        if self.properties['region2'] is not None \\\n",
    "           and self.properties['links_type'] != 'squares':\n",
    "            self.log.warning(\"*WARNING* for section \"\n",
    "                             f\"{self.properties['section_name']}\"\n",
    "                             \" a region2 was set but \"\n",
    "                             \"links_type was not set to squares.\"\n",
    "                             \"region2 will be ignored.\\n\")\n",
    "            self.properties['region2'] = None\n",
    "        if self.properties['region2'] is not None:\n",
    "            region2 = get_region(self.properties['region2'])\n",
    "            if self.properties['region'] is not None:\n",
    "                self.properties['region'].append(region2)\n",
    "            self.region2 = region2\n",
    "            if self.properties['use_middle']:\n",
    "                self.log.warning(\"*WARNING* for section \"\n",
    "                                 f\"{self.properties['section_name']}\"\n",
    "                                 \" a use_middle was set to true \"\n",
    "                                 \"but this is incompatible with squares.\"\n",
    "                                 \"\\n\")\n",
    "                self.properties['use_middle'] = False\n",
    "\n",
    "        self.interval_tree, min_score, max_score, has_score = self.process_link_file(self.properties['region'])\n",
    "        if self.properties['line_width'] is None and not has_score:\n",
    "            self.log.warning(\"*WARNING* for section \"\n",
    "                             f\"{self.properties['section_name']}\"\n",
    "                             \" no line_width has been set but some \"\n",
    "                             \"lines do not have scores.\"\n",
    "                             \"line_width has been set to \"\n",
    "                             \"0.5.\\n\")\n",
    "            self.properties['line_width'] = 0.5\n",
    "\n",
    "        self.colormap = None\n",
    "        # check if the color given is a color map\n",
    "        is_colormap = self.process_color('color', colormap_possible=True,\n",
    "                                         default_value_is_colormap=False)\n",
    "        if is_colormap:\n",
    "            if not has_score:\n",
    "                self.log.warning(\"*WARNING* for section \"\n",
    "                                 f\"{self.properties['section_name']}\"\n",
    "                                 \" a colormap was chosen but some \"\n",
    "                                 \"lines do not have scores.\"\n",
    "                                 \"Color has been set to \"\n",
    "                                 f\"{DEFAULT_LINKS_COLOR}.\\n\")\n",
    "                self.properties['color'] = DEFAULT_LINKS_COLOR\n",
    "            else:\n",
    "                self.colormap = self.properties['color']\n",
    "\n",
    "        if self.colormap is not None:\n",
    "            if self.properties['min_value'] is not None:\n",
    "                min_score = self.properties['min_value']\n",
    "            if self.properties['max_value'] is not None:\n",
    "                max_score = self.properties['max_value']\n",
    "\n",
    "            norm = matplotlib.colors.Normalize(vmin=min_score,\n",
    "                                               vmax=max_score)\n",
    "\n",
    "            cmap = matplotlib.cm.get_cmap(self.properties['color'])\n",
    "            self.colormap = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "\n",
    "        if self.properties['compact_arcs_level'] == '2' and \\\n",
    "           self.properties['ylim'] is not None:\n",
    "            self.log.warning(\"*WARNING* for section \"\n",
    "                             f\"{self.properties['section_name']}\"\n",
    "                             \" a ylim was set but \"\n",
    "                             \"compact_arcs_level was set to 2.\"\n",
    "                             \"ylim will be ignored.\\n\")\n",
    "            self.properties['ylim'] = None\n",
    "\n",
    "    def plot(self, ax, chrom_region, region_start, region_end):\n",
    "        \"\"\"\n",
    "        Makes an arc connecting two points on a linear scale representing\n",
    "        interactions between Hi-C bins.\n",
    "        Or a diamong or a triangle highlighting interactions.\n",
    "        Or a square.\n",
    "        :param ax: matplotlib axis\n",
    "        \"\"\"\n",
    "        self.max_height = 0\n",
    "        count = 0\n",
    "\n",
    "        if chrom_region not in list(self.interval_tree):\n",
    "            chrom_region_before = chrom_region\n",
    "            chrom_region = change_chrom_names(chrom_region)\n",
    "            if chrom_region not in list(self.interval_tree):\n",
    "                self.log.warning(\"*Warning*\\nNeither \" + chrom_region_before\n",
    "                                 + \" nor \" + chrom_region + \" exists as a \"\n",
    "                                 \"chromosome name inside the link file. \"\n",
    "                                 \"This will generate an empty track!!\\n\")\n",
    "                return\n",
    "\n",
    "        arcs_in_region = sorted(self.interval_tree[chrom_region][region_start:region_end])\n",
    "\n",
    "        for idx, interval in enumerate(arcs_in_region):\n",
    "            if self.properties['links_type'] == 'squares':\n",
    "                plotting_sides = {'as_in_data': False, 'mirrored': False}\n",
    "                start1, end1, start2, end2, _ = interval.data\n",
    "                if self.properties['region2'] is None:\n",
    "                    temp_region2 = [chrom_region, region_start, region_end]\n",
    "                else:\n",
    "                    temp_region2 = self.region2\n",
    "                if chrom_region not in [temp_region2[0], change_chrom_names(temp_region2[0])]:\n",
    "                    # This is a trans:\n",
    "                    plotting_sides['as_in_data'] = True\n",
    "                else:\n",
    "                    # We need to check which sides need to be plotted:\n",
    "                    if (start1 < region_end and end1 > region_start) \\\n",
    "                       and (start2 < temp_region2[2] and end2 > temp_region2[1]):\n",
    "                        plotting_sides['as_in_data'] = True\n",
    "                    if (start2 < region_end and end2 > region_start) \\\n",
    "                       and (start1 < temp_region2[2] and end1 > temp_region2[1]):\n",
    "                        plotting_sides['mirrored'] = True\n",
    "                    if not plotting_sides['as_in_data'] and not plotting_sides['mirrored']:\n",
    "                        continue\n",
    "            else:\n",
    "                # skip intervals whose start and end are outside the plotted region\n",
    "                if interval.begin < region_start and interval.end > region_end:\n",
    "                    continue\n",
    "\n",
    "            if self.properties['line_width'] is not None:\n",
    "                self.current_line_width = float(self.properties['line_width'])\n",
    "            else:\n",
    "                self.current_line_width = 0.5 * np.sqrt(interval.data[4])\n",
    "\n",
    "            if self.properties['links_type'] == 'triangles':\n",
    "                self.plot_triangles(ax, interval)\n",
    "            elif self.properties['links_type'] == 'loops':\n",
    "                self.plot_loops(ax, interval.data)\n",
    "            elif self.properties['links_type'] == 'squares':\n",
    "                if plotting_sides['as_in_data']:\n",
    "                    self.plot_squares(ax, interval.data)\n",
    "                if plotting_sides['mirrored']:\n",
    "                    self.plot_squares(ax, interval.data, mirrored=True)\n",
    "            else:\n",
    "                self.plot_arcs(ax, interval)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        self.log.debug(f\"{count} were links plotted\")\n",
    "        if self.properties['overlay_previous'] != 'share-y':\n",
    "            if self.properties['links_type'] == 'squares':\n",
    "                if self.properties['region2'] is None:\n",
    "                    region_start_y = region_start\n",
    "                    region_end_y = region_end\n",
    "                else:\n",
    "                    region_start_y = self.region2[1]\n",
    "                    region_end_y = self.region2[2]\n",
    "                if self.properties['orientation'] == 'inverted':\n",
    "                    ax.set_ylim(region_start_y, region_end_y)\n",
    "                else:\n",
    "                    ax.set_ylim(region_end_y, region_start_y)\n",
    "            else:\n",
    "                # the arc height is equal to the radius, the track height is the largest\n",
    "                # radius plotted plus an small increase to avoid cropping of the arcs\n",
    "                self.max_height *= 1.1\n",
    "                if self.properties['ylim'] is None:\n",
    "                    ymax = self.max_height\n",
    "                else:\n",
    "                    if self.properties['compact_arcs_level'] == '1':\n",
    "                        ymax = np.sqrt(self.properties['ylim'])\n",
    "                    else:\n",
    "                        ymax = self.properties['ylim']\n",
    "                if self.properties['orientation'] == 'inverted':\n",
    "                    ax.set_ylim(ymax, -1)\n",
    "                else:\n",
    "                    ax.set_ylim(-1, ymax)\n",
    "\n",
    "    def plot_y_axis(self, axis, plot_ax):\n",
    "        if self.colormap is not None and self.properties['overlay_previous'] == 'no':\n",
    "            self.colormap.set_array([])\n",
    "            GenomeTrack.plot_custom_cobar(self, axis, fraction=1)\n",
    "\n",
    "    def plot_arcs(self, ax, interval):\n",
    "\n",
    "        width = (interval.end - interval.begin)\n",
    "        if self.properties['compact_arcs_level'] == '1':\n",
    "            half_height = np.sqrt(width)\n",
    "        elif self.properties['compact_arcs_level'] == '2':\n",
    "            half_height = 1000\n",
    "        else:\n",
    "            half_height = width\n",
    "        center = interval.begin + width / 2\n",
    "        if half_height > self.max_height:\n",
    "            self.max_height = half_height\n",
    "        # I think this was an error...\n",
    "        # ax.plot([center], [diameter])\n",
    "        if self.colormap:\n",
    "            # translate score field\n",
    "            # into a color\n",
    "            rgb = self.colormap.to_rgba(interval.data[4])\n",
    "        else:\n",
    "            rgb = self.properties['color']\n",
    "        ax.add_patch(Arc((center, 0), width,\n",
    "                         2 * half_height, 0, 0, 180, color=rgb,\n",
    "                         linewidth=self.current_line_width,\n",
    "                         ls=self.properties['line_style']))\n",
    "\n",
    "    def plot_triangles(self, ax, interval):\n",
    "        x1 = interval.begin\n",
    "        x2 = x1 + float(interval.end - interval.begin) / 2\n",
    "        x3 = interval.end\n",
    "        y1 = 0\n",
    "        if self.properties['compact_arcs_level'] == '1':\n",
    "            y2 = np.sqrt(interval.end - interval.begin)\n",
    "        elif self.properties['compact_arcs_level'] == '2':\n",
    "            y2 = 1000\n",
    "        else:\n",
    "            y2 = (interval.end - interval.begin)\n",
    "\n",
    "        if self.colormap:\n",
    "            # translate score field\n",
    "            # into a color\n",
    "            rgb = self.colormap.to_rgba(interval.data[4])\n",
    "        else:\n",
    "            rgb = self.properties['color']\n",
    "\n",
    "        triangle = Polygon(np.array([[x1, y1], [x2, y2], [x3, y1]]),\n",
    "                           closed=False,\n",
    "                           facecolor='none', edgecolor=rgb,\n",
    "                           linewidth=self.current_line_width,\n",
    "                           ls=self.properties['line_style'])\n",
    "        ax.add_artist(triangle)\n",
    "        if y2 > self.max_height:\n",
    "            self.max_height = y2\n",
    "\n",
    "    def plot_loops(self, ax, loop):\n",
    "        \"\"\"\n",
    "              \" <- 2\n",
    "        3->  \"  \" <- 1\n",
    "               \" <- 0\n",
    "            \"\"\"\n",
    "        width1 = loop[1] - loop[0]\n",
    "        width2 = loop[3] - loop[2]\n",
    "        x0 = (loop[1] + loop[2]) / 2\n",
    "        y0 = loop[2] - loop[1]\n",
    "\n",
    "        x1 = x0 + width2 / 2\n",
    "        y1 = y0 + width2\n",
    "\n",
    "        x2 = (loop[0] + loop[3]) / 2\n",
    "        y2 = loop[3] - loop[0]\n",
    "\n",
    "        x3 = x0 - width1 / 2\n",
    "        y3 = y0 + width1\n",
    "\n",
    "        if self.colormap:\n",
    "            # translate score field\n",
    "            # into a color\n",
    "            rgb = self.colormap.to_rgba(loop[4])\n",
    "        else:\n",
    "            rgb = self.properties['color']\n",
    "\n",
    "        rectangle = Polygon(np.array([[x0, y0], [x1, y1], [x2, y2], [x3, y3]]),\n",
    "                            facecolor='none', edgecolor=rgb,\n",
    "                            linewidth=self.current_line_width,\n",
    "                            ls=self.properties['line_style'])\n",
    "        ax.add_artist(rectangle)\n",
    "        if min(y0, y1, y2, y3) < 0:\n",
    "            rectangle_flip = Polygon(np.array([[x0, -y0], [x1, -y1], [x2, -y2], [x3, -y3]]),\n",
    "                                     facecolor='none', edgecolor=rgb,\n",
    "                                     linewidth=self.current_line_width,\n",
    "                                     ls=self.properties['line_style'])\n",
    "            ax.add_artist(rectangle_flip)\n",
    "        if y2 > self.max_height:\n",
    "            self.max_height = y2\n",
    "\n",
    "    def plot_squares(self, ax, loop, mirrored=False):\n",
    "        \"\"\"\n",
    "        mirrored means mirrored regarding to the diagonal\n",
    "        (start2, end2, start1, end1)\n",
    "        2->  \"  \" <- 1\n",
    "        3->  \"  \" <- 0\n",
    "        \"\"\"\n",
    "        # loop is start1, end1, start2, end2, score\n",
    "        if not mirrored:\n",
    "            x0 = loop[1]\n",
    "            y0 = loop[2]\n",
    "            y1 = loop[3]\n",
    "            x2 = loop[0]\n",
    "        else:\n",
    "            x0 = loop[3]\n",
    "            y0 = loop[0]\n",
    "            y1 = loop[1]\n",
    "            x2 = loop[2]\n",
    "\n",
    "        x1 = x0\n",
    "        y2 = y1\n",
    "\n",
    "        x3 = x2\n",
    "        y3 = y0\n",
    "\n",
    "        if self.colormap:\n",
    "            # translate score field\n",
    "            # into a color\n",
    "            rgb = self.colormap.to_rgba(loop[4])\n",
    "        else:\n",
    "            rgb = self.properties['color']\n",
    "        rectangle = Polygon(np.array([[x0, y0], [x1, y1], [x2, y2], [x3, y3]]),\n",
    "                            facecolor='none', edgecolor=rgb,\n",
    "                            linewidth=self.current_line_width,\n",
    "                            ls=self.properties['line_style'])\n",
    "        ax.add_artist(rectangle)\n",
    "\n",
    "    def process_link_file(self, plot_regions):\n",
    "        # the file format expected is similar to file format of links in\n",
    "        # circos:\n",
    "        # chr1 100 200 chr1 250 300 0.5\n",
    "        # where the last value is a score.\n",
    "\n",
    "        if plot_regions is None:\n",
    "            file_to_open = self.properties['file']\n",
    "        else:\n",
    "            # To be sure we do not miss links we will intersect with bed with\n",
    "            # only chromosomes used in plot_regions\n",
    "            plot_regions_adapted = [(chrom, 0, HUGE_NUMBER) for chrom, __, __ in plot_regions]\n",
    "            file_to_open = temp_file_from_intersect(self.properties['file'],\n",
    "                                                    plot_regions_adapted)\n",
    "\n",
    "        valid_intervals = 0\n",
    "        interval_tree = {}\n",
    "        line_number = 0\n",
    "        has_score = True\n",
    "        max_score = float('-inf')\n",
    "        min_score = float('inf')\n",
    "        file_h = opener(file_to_open)\n",
    "        for line in tqdm(file_h.readlines()):\n",
    "            line_number += 1\n",
    "            line = to_string(line)\n",
    "            if line.startswith('browser') or line.startswith('track') or line.startswith('#'):\n",
    "                continue\n",
    "            try:\n",
    "                chrom1, start1, end1, chrom2, start2, end2 = line.strip().split('\\t')[:6]\n",
    "            except Exception as detail:\n",
    "                raise InputError('File not valid. The format is chrom1'\n",
    "                                 ' start1, end1, '\n",
    "                                 f'chrom2, start2, end2\\nError: {detail}\\n'\n",
    "                                 f' in line\\n {line}')\n",
    "            if chrom1 != chrom2:\n",
    "                if self.properties['region2'] is None:\n",
    "                    self.log.warning(f\"Only links in same chromosome are used. Skipping line\\n{line}\\n\")\n",
    "                    continue\n",
    "                else:\n",
    "                    # I keep if chrom1 or chrom2 matches the region2\n",
    "                    # And store with chrom2 corresponding to region2\n",
    "                    possible_chrom_region2 = [self.region2[0], change_chrom_names(self.region2[0])]\n",
    "                    if chrom1 in possible_chrom_region2:\n",
    "                        is_trans = True\n",
    "                        # I switch:\n",
    "                        chrom1, chrom2 = chrom2, chrom1\n",
    "                        start1, start2 = start2, start1\n",
    "                        end1, end2 = end2, end1\n",
    "                    elif chrom2 in possible_chrom_region2:\n",
    "                        is_trans = True\n",
    "                    else:\n",
    "                        self.log.warning(f\"Only links with a chromosome matching region2 are used. Skipping line\\n{line}\\n\")\n",
    "                        continue\n",
    "            else:\n",
    "                is_trans = False\n",
    "\n",
    "            try:\n",
    "                score = line.strip().split('\\t')[6]\n",
    "            except IndexError:\n",
    "                has_score = False\n",
    "                score = np.nan\n",
    "\n",
    "            try:\n",
    "                start1 = int(start1)\n",
    "                end1 = int(end1)\n",
    "                start2 = int(start2)\n",
    "                end2 = int(end2)\n",
    "            except ValueError as detail:\n",
    "                raise InputError(f\"Error reading line: {line_number}. One of the fields is not \"\n",
    "                                 f\"an integer.\\nError message: {detail}\")\n",
    "\n",
    "            assert start1 <= end1, f\"Error in line #{line_number}, end1 larger than start1 in {line}\"\n",
    "            assert start2 <= end2, f\"Error in line #{line_number}, end2 larger than start2 in {line}\"\n",
    "\n",
    "            if has_score:\n",
    "                try:\n",
    "                    score = float(score)\n",
    "                except ValueError as detail:\n",
    "                    self.log.warning(f\"Warning: reading line: {line}. The score is not valid {score} will not be used. \"\n",
    "                                     f\"\\nError message: {detail}\\n\")\n",
    "                    score = np.nan\n",
    "                    has_score = False\n",
    "                else:\n",
    "                    if score < min_score:\n",
    "                        min_score = score\n",
    "                    if score > max_score:\n",
    "                        max_score = score\n",
    "\n",
    "            if chrom1 not in interval_tree:\n",
    "                interval_tree[chrom1] = IntervalTree()\n",
    "            if start2 < start1 and not is_trans:\n",
    "                start1, start2 = start2, start1\n",
    "                end1, end2 = end2, end1\n",
    "            if self.properties['use_middle']:\n",
    "                mid1 = (start1 + end1) / 2\n",
    "                mid2 = (start2 + end2) / 2\n",
    "                if mid1 < mid2:\n",
    "                    interval_tree[chrom1].add(Interval(mid1, mid2, [start1, end1, start2, end2, score]))\n",
    "                else:\n",
    "                    interval_tree[chrom1].add(Interval(mid2, mid1, [start2, end2, start1, end1, score]))\n",
    "            else:\n",
    "                if not is_trans:\n",
    "                    # each interval spans from the smallest start to the largest end\n",
    "                    interval_tree[chrom1].add(Interval(start1, max(end1, end2), [start1, end1, start2, end2, score]))\n",
    "                else:\n",
    "                    # For the trans we keep start1 and end1\n",
    "                    interval_tree[chrom1].add(Interval(start1, end1, [start1, end1, start2, end2, score]))\n",
    "            valid_intervals += 1\n",
    "\n",
    "        if valid_intervals == 0:\n",
    "            self.log.warning(f\"No valid intervals were found in file {self.properties['file']}.\\n\")\n",
    "\n",
    "        file_h.close()\n",
    "        return interval_tree, min_score, max_score, has_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygenometracks.tracks.BedGraphTrack import BedGraphTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_track_properties = {\n",
    "    'file' : '/data/leslie/jiaxin/PANC/data/bpnet/bam_files/Dataset6_sample1_test.bedGraph',\n",
    "    # Set necessary and optional properties\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████████████████████████████████████████████▍                                               | 102378169/212075243 [1:37:29<1:24:34, 21618.53it/s]"
     ]
    }
   ],
   "source": [
    "bed_track = BedGraphTrack(properties_dict = bed_track_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygenometracks.tracks.LinksTrack import LinksTrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_track_properties = {\n",
    "    'file': '/path/to/your/datafile.links',\n",
    "    # Set other necessary and optional properties\n",
    "    'links_type': 'arcs',\n",
    "    'color': 'red',\n",
    "    'line_style': 'solid',\n",
    "    # ... other properties ...\n",
    "}\n",
    "\n",
    "# Create an instance of the LinksTrack class\n",
    "links_track = LinksTrack(properties_dict=links_track_properties)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSS request function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
